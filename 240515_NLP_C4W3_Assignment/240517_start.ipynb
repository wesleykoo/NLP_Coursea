{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca79e2db-0074-43c8-b745-6d7c1ab887fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ba181",
   "metadata": {},
   "source": [
    "# Importing the Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b703c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /home/codespace/anaconda3/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: numpy in /home/codespace/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in /home/codespace/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: tensorflow_text in /home/codespace/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow_text) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow_text) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (13.3.5)\n",
      "Requirement already satisfied: namex in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/codespace/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow_text) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow_text) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow_text) (0.1.0)\n",
      "Collecting dlai_grader\n",
      "  Downloading dlai-grader-1.18.0.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=5.1.3 in /home/codespace/anaconda3/lib/python3.11/site-packages (from dlai_grader) (5.9.2)\n",
      "Collecting jupytext>=1.13.0 (from dlai_grader)\n",
      "  Downloading jupytext-1.16.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jupytext>=1.13.0->dlai_grader) (2.2.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /home/codespace/anaconda3/lib/python3.11/site-packages (from jupytext>=1.13.0->dlai_grader) (0.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/anaconda3/lib/python3.11/site-packages (from jupytext>=1.13.0->dlai_grader) (23.1)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/anaconda3/lib/python3.11/site-packages (from jupytext>=1.13.0->dlai_grader) (6.0.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/codespace/anaconda3/lib/python3.11/site-packages (from nbformat>=5.1.3->dlai_grader) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/codespace/anaconda3/lib/python3.11/site-packages (from nbformat>=5.1.3->dlai_grader) (4.19.2)\n",
      "Requirement already satisfied: jupyter-core in /home/codespace/anaconda3/lib/python3.11/site-packages (from nbformat>=5.1.3->dlai_grader) (5.5.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from nbformat>=5.1.3->dlai_grader) (5.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.1.3->dlai_grader) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.1.3->dlai_grader) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.1.3->dlai_grader) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.1.3->dlai_grader) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/codespace/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=1.0->jupytext>=1.13.0->dlai_grader) (0.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/codespace/anaconda3/lib/python3.11/site-packages (from jupyter-core->nbformat>=5.1.3->dlai_grader) (3.10.0)\n",
      "Downloading jupytext-1.16.2-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: dlai_grader\n",
      "  Building wheel for dlai_grader (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlai_grader: filename=dlai_grader-1.18.0-py3-none-any.whl size=18532 sha256=9e68bb8d0d553fcfa277fa6ada008ac491d24f3020372183e4435c704ba9f5e9\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/fc/b9/77/0a353071ecfff56316f06e9aaf8dfaa1e77880667884c5555c\n",
      "Successfully built dlai_grader\n",
      "Installing collected packages: jupytext, dlai_grader\n",
      "Successfully installed dlai_grader-1.18.0 jupytext-1.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_text\n",
    "!pip install dlai_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d16e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "from termcolor import colored\n",
    "import string\n",
    "import textwrap\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow_text as tf_text\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformer_utils \n",
    "import utils\n",
    "\n",
    "# Will come in handy later\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45733b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import w3_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3c77f",
   "metadata": {},
   "source": [
    "# 1.2 C4 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b6ce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: \n",
      "\n",
      "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'}\n",
      "\n",
      "\n",
      "Example 2: \n",
      "\n",
      "{'text': 'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.'}\n",
      "\n",
      "\n",
      "Example 3: \n",
      "\n",
      "{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.'}\n",
      "\n",
      "\n",
      "Example 4: \n",
      "\n",
      "{'text': \"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\"}\n",
      "\n",
      "\n",
      "Example 5: \n",
      "\n",
      "{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure.'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load example data stored in 'data/c4-en-10k.jsonl'\n",
    "each line is a json object. \n",
    "strip lines from the example data.\n",
    "'''\n",
    "with open('data/c4-en-10k.jsonl') as f:\n",
    "    examples_jsons = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Printing the examples to see how the data looks like\n",
    "for i in range(5):\n",
    "    print(f'Example {i+1}: \\n\\n{examples_jsons[i]}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ac3506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example text:\n",
      "\n",
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
      "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract the text from the examples\n",
    "natural_language_texts = [example['text'] for example in examples_jsons]\n",
    "\n",
    "# print the first example text\n",
    "print(f'First example text:\\n\\n{natural_language_texts[0]}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129eb590",
   "metadata": {},
   "source": [
    "## 1.4 Decode to Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7426f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create tokenizer by using SentencePieceTokenizer.\n",
    "- open \"./models/sentencepiece.model\" file\n",
    "- create SentencePieceTokenizer object\n",
    "'''\n",
    "with open('./models/sentencepiece.model', 'rb') as f:\n",
    "    pre_trained_tokenizer = f.read()\n",
    "\n",
    "tokenizer = tf_text.SentencepieceTokenizer(pre_trained_tokenizer, out_type=tf.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a2f70",
   "metadata": {},
   "source": [
    "Special token:\n",
    "PAD, EOS = 0, 1\n",
    "In this tokenizer the string </s> is used as EOS token. By default, the tokenizer does not add the EOS to the end of each sentence, so you need to add it manually when required. Let's verify what id correspond to this token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35e1b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS: 1\n"
     ]
    }
   ],
   "source": [
    "eos = tokenizer.string_to_id(\"</s>\").numpy()\n",
    "print(\"EOS: \" + str(eos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f50f9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t-->\tTokenization\n",
      "----------------------------------------\n",
      "Foil    \t-->\t[4452, 173]\n",
      "plaid   \t-->\t[30772]\n",
      "lycra   \t-->\t[3, 120, 2935]\n",
      "and     \t-->\t[11]\n",
      "spandex \t-->\t[8438, 26, 994]\n",
      "shortall\t-->\t[710, 1748]\n",
      "with    \t-->\t[28]\n",
      "metallic\t-->\t[18813]\n",
      "slinky  \t-->\t[3, 7, 4907, 63]\n",
      "insets. \t-->\t[16, 2244, 7, 5]\n",
      "Attached\t-->\t[28416, 15, 26]\n",
      "metallic\t-->\t[18813]\n",
      "elastic \t-->\t[15855]\n",
      "belt    \t-->\t[6782]\n",
      "with    \t-->\t[28]\n",
      "O-ring. \t-->\t[411, 18, 1007, 5]\n",
      "Headband\t-->\t[3642, 3348]\n",
      "included.\t-->\t[1285, 5]\n",
      "Great   \t-->\t[1651]\n",
      "hip     \t-->\t[5436]\n",
      "hop     \t-->\t[13652]\n",
      "or      \t-->\t[42]\n",
      "jazz    \t-->\t[9948]\n",
      "dance   \t-->\t[2595]\n",
      "costume.\t-->\t[11594, 5]\n",
      "Made    \t-->\t[6465]\n",
      "in      \t-->\t[16]\n",
      "the     \t-->\t[8]\n",
      "USA.    \t-->\t[2312, 5]\n"
     ]
    }
   ],
   "source": [
    "# print the encoding of each word in natural_language_texts[2] to see how subwards are tokenized\n",
    "# print the following format word --> tokenized word\n",
    "tokenized_text = [(list(tokenizer.tokenize(word).numpy()), word) for word in natural_language_texts[2].split()]\n",
    "\n",
    "print(\"Word\\t\\t-->\\tTokenization\")\n",
    "print(\"-\"*40)\n",
    "for element in tokenized_text:\n",
    "    print(f\"{element[1]:<8}\\t-->\\t{element[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
